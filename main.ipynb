{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "print(torch.__version__)\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_agnostic():\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"Device:\", device)\n",
    "    return device\n",
    "\n",
    "device = device_agnostic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the image directory\n",
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed to make sure the results are reproducible\n",
    "#random.seed(42)\n",
    "\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "random_image_path = random.choice(image_path_list)\n",
    "print(random_image_path)\n",
    "image_class = random_image_path.parent.name # OR .stem\n",
    " \n",
    "print(image_class)\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f\"Path: {random_image_path}\")\n",
    "print(f\"Class: {image_class}\")\n",
    "print(f\"Size: {img.size}\")\n",
    "img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_as_array = np.array(img)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"{image_class}, {img_as_array.shape}\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data and setup the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# From pytorch website:\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize(299),\n",
    "#     transforms.CenterCrop(299),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# train_transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(299),\n",
    "#         transforms.TrivialAugmentWide(num_magnitude_bins=10),\n",
    "#         transforms.ToTensor(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# test_transform = transforms.Compose(\n",
    "#     [transforms.Resize((299)), transforms.ToTensor()]\n",
    "# )\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = train_transform\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
    "\n",
    "# Turn datasets into dataloaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set batch size and number of workers\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f\"Using {NUM_WORKERS} workers\")\n",
    "train_dataloader_simple = DataLoader(\n",
    "    dataset=train_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader_simple = DataLoader(\n",
    "    dataset=test_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=True , # drop the last incomplete batch if the dataset size is not divisible by the batch size\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprting InceptionV3 model for transfer learning\n",
    "from pickletools import optimize\n",
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.aux_logits = (\n",
    "    False  # Remove auxiliary classifier layer, They are used when training on Imagenet\n",
    ")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all the parameters\n",
    "\n",
    "num_ftrs = model.fc.in_features  # Get the number of features of the last layer\n",
    "\n",
    "model.fc = nn.Linear(\n",
    "    num_ftrs, 3\n",
    ")  # Replace the last layer with a linear layer with 3 outputs\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchinfo\n",
    "# torchinfo.summary(model, input_size=(3, 299, 299))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_step\n",
    "from rich.progress import track\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    # set up loss and train accuracy\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    # Make the track bar delete after it's done\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # 23:20:58\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy metric\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(\n",
    "            y_pred\n",
    "        )  # <- this is the same as torch.sum(y_pred_class == y) / len(y_pred)\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "\n",
    "    train_loss = train_loss / len(\n",
    "        dataloader\n",
    "    )  # <- len(dataloader) is the number of batches in the dataloader\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_step\n",
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device=device,\n",
    "):\n",
    "    # Model to eval mode\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(\n",
    "                dim=1\n",
    "            )  # <- softmax is not needed for argmax\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(\n",
    "        dataloader\n",
    "    )  # <- len(dataloader) is the number of batches in the dataloader\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int = 5,\n",
    "):\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "    from timeit import default_timer as timer\n",
    "\n",
    "    for epoch in track(range(epochs)):\n",
    "        epoch_train_time = timer()\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer)\n",
    "        epoch_test_time = timer()\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn)\n",
    "        epoch_stop_time = timer()\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{epochs} |\"\n",
    "            f\"Train_loss: {train_loss:.4f} |\"\n",
    "            f\"train_acc: {train_acc:.4f} |\"\n",
    "            f\"test_loss: {test_loss:.4f} |\"\n",
    "            f\"test_acc: {test_acc:.4f} |\\n\"\n",
    "            f\"train time: {epoch_test_time -epoch_train_time:.4f} secs |\"\n",
    "            f\"test time: {epoch_stop_time - epoch_test_time :.4f} secs |\"\n",
    "            f\"total time: {epoch_stop_time - epoch_train_time:.4f} secs |\\n\"\n",
    "            f\"------------------------------------------------------\"\n",
    "        )\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHES = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "timer_start = timer()  # ðŸ•‘\n",
    "\n",
    "model_0_results = train(\n",
    "    model,\n",
    "    train_dataloader_simple,\n",
    "    test_dataloader_simple,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    NUM_EPOCHES,\n",
    ")\n",
    "\n",
    "timer_stop = timer()  # ðŸ•‘\n",
    "\n",
    "print(f\"Training took {timer_stop - timer_start:.3f} seconds or {(timer_stop - timer_start) / 60:.3f} minutes on device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16fac55749e6291cf1fb1cca0009465826520f74af157c49a742eded4a6fab47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
